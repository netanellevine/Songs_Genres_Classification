{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc725782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\talia\\pycharmprojects\\nlp\\venv\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1028f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talia\\AppData\\Local\\Temp\\ipykernel_17148\\2278801785.py:6: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  allData.drop(columns=[\"genre_id\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Loading and splitting the data\n",
    "allData = pd.read_csv(\"data/songs_with_genre.csv\", index_col=0,\n",
    "                      header=[0, 1, 2])\n",
    "generes = allData[\"genre_id\"]\n",
    "genres_index = pd.read_csv(\"data/genres_index.csv\", index_col=0)\n",
    "allData.drop(columns=[\"genre_id\"], inplace=True)\n",
    "data_x = allData\n",
    "data_x.columns = range(data_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c4751da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(data_x, axis=0)\n",
    "sigma = (np.std(data_x, axis=0))\n",
    "data_x = (data_x - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187e24cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talia\\AppData\\Local\\Temp\\ipykernel_17148\\3616334520.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  generes[0] = generes[0] - 1\n",
      "C:\\Users\\talia\\AppData\\Local\\Temp\\ipykernel_17148\\3616334520.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  generes[0] = data_y\n"
     ]
    }
   ],
   "source": [
    "#Creating the right lables\n",
    "generes.columns = range(generes.shape[1])\n",
    "targets = OneHotEncoder().fit_transform(genres_index).toarray()\n",
    "generes[0] = generes[0] - 1\n",
    "data_y = [targets[i - 1] for i in generes[0]]\n",
    "generes[0] = data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48e06e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(49598, 1)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = generes.copy()\n",
    "test.rename(columns={0: \"oneHotVector\"}, inplace=True)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfdd3a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49598, 161)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   0    1    2    3    4    5    6    7    8    9    ...  151  152  153  154  \\\n0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n\n   155  156  157  158  159  160  \n0  0.0  0.0  0.0  0.0  0.0  0.0  \n1  0.0  0.0  0.0  0.0  0.0  0.0  \n2  0.0  0.0  0.0  0.0  0.0  0.0  \n3  0.0  0.0  0.0  0.0  0.0  0.0  \n4  0.0  0.0  0.0  0.0  0.0  0.0  \n\n[5 rows x 161 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>151</th>\n      <th>152</th>\n      <th>153</th>\n      <th>154</th>\n      <th>155</th>\n      <th>156</th>\n      <th>157</th>\n      <th>158</th>\n      <th>159</th>\n      <th>160</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 161 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = pd.DataFrame(test[\"oneHotVector\"].to_list(), columns=range(161))\n",
    "print(split.shape)\n",
    "split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3429f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "split.index = generes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "046fd651",
   "metadata": {},
   "outputs": [],
   "source": [
    "generes = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda60824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train,test and validation sets\n",
    "x_train, x_rest, y_train, y_rest = train_test_split(data_x, generes, train_size=0.8)\n",
    "x_test, x_valid, y_test, y_valid = train_test_split(x_rest, y_rest, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8437a1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "               0         1         2         3         4         5    \\\ntrack_id                                                               \n6631      0.179238  0.361781  0.403628  0.468626  0.406638  0.467347   \n147195   -0.087717 -0.040546 -0.189276 -0.127388 -0.471707 -0.290641   \n63354     0.478918  0.136843  0.031943  0.243040  0.484002 -0.186089   \n23551     0.038673 -0.032175 -0.153968 -0.408782 -0.363398  0.485231   \n30327    -0.043228  0.059844 -0.098564 -0.108816 -0.169434  0.162772   \n\n               6         7         8         9    ...       508       509  \\\ntrack_id                                          ...                       \n6631      0.097726  0.215505 -0.363119 -0.024478  ... -1.095863 -0.462879   \n147195   -0.076219 -0.310930 -0.326858 -0.104819  ...  0.694617  0.619794   \n63354     0.026491 -0.229141 -0.310380 -0.106063  ...  0.299013  0.292569   \n23551     0.063833 -0.051719 -0.474776 -0.157346  ... -1.005212 -0.636474   \n30327    -0.034107  0.113279  0.336566 -0.003216  ... -0.739609  0.251306   \n\n               510       511       512       513       514       515  \\\ntrack_id                                                               \n6631     -1.137261 -0.317722 -0.811422  1.047912  0.965160  0.403011   \n147195    0.624621 -0.293977 -0.867914 -0.498694 -0.396174 -0.483419   \n63354     1.715968 -0.238810 -0.227671 -0.252732 -0.291456 -0.483419   \n23551    -1.060995 -0.265033  0.261927  0.475789  0.396691 -0.483419   \n30327    -0.288614 -0.280471 -1.015869 -0.525669 -0.590650 -0.483419   \n\n               516       517  \ntrack_id                      \n6631     -0.852925  0.283139  \n147195   -0.662453 -0.712240  \n63354    -0.326257 -0.047746  \n23551    -0.462064  0.753480  \n30327    -0.495948 -0.308999  \n\n[5 rows x 518 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>508</th>\n      <th>509</th>\n      <th>510</th>\n      <th>511</th>\n      <th>512</th>\n      <th>513</th>\n      <th>514</th>\n      <th>515</th>\n      <th>516</th>\n      <th>517</th>\n    </tr>\n    <tr>\n      <th>track_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6631</th>\n      <td>0.179238</td>\n      <td>0.361781</td>\n      <td>0.403628</td>\n      <td>0.468626</td>\n      <td>0.406638</td>\n      <td>0.467347</td>\n      <td>0.097726</td>\n      <td>0.215505</td>\n      <td>-0.363119</td>\n      <td>-0.024478</td>\n      <td>...</td>\n      <td>-1.095863</td>\n      <td>-0.462879</td>\n      <td>-1.137261</td>\n      <td>-0.317722</td>\n      <td>-0.811422</td>\n      <td>1.047912</td>\n      <td>0.965160</td>\n      <td>0.403011</td>\n      <td>-0.852925</td>\n      <td>0.283139</td>\n    </tr>\n    <tr>\n      <th>147195</th>\n      <td>-0.087717</td>\n      <td>-0.040546</td>\n      <td>-0.189276</td>\n      <td>-0.127388</td>\n      <td>-0.471707</td>\n      <td>-0.290641</td>\n      <td>-0.076219</td>\n      <td>-0.310930</td>\n      <td>-0.326858</td>\n      <td>-0.104819</td>\n      <td>...</td>\n      <td>0.694617</td>\n      <td>0.619794</td>\n      <td>0.624621</td>\n      <td>-0.293977</td>\n      <td>-0.867914</td>\n      <td>-0.498694</td>\n      <td>-0.396174</td>\n      <td>-0.483419</td>\n      <td>-0.662453</td>\n      <td>-0.712240</td>\n    </tr>\n    <tr>\n      <th>63354</th>\n      <td>0.478918</td>\n      <td>0.136843</td>\n      <td>0.031943</td>\n      <td>0.243040</td>\n      <td>0.484002</td>\n      <td>-0.186089</td>\n      <td>0.026491</td>\n      <td>-0.229141</td>\n      <td>-0.310380</td>\n      <td>-0.106063</td>\n      <td>...</td>\n      <td>0.299013</td>\n      <td>0.292569</td>\n      <td>1.715968</td>\n      <td>-0.238810</td>\n      <td>-0.227671</td>\n      <td>-0.252732</td>\n      <td>-0.291456</td>\n      <td>-0.483419</td>\n      <td>-0.326257</td>\n      <td>-0.047746</td>\n    </tr>\n    <tr>\n      <th>23551</th>\n      <td>0.038673</td>\n      <td>-0.032175</td>\n      <td>-0.153968</td>\n      <td>-0.408782</td>\n      <td>-0.363398</td>\n      <td>0.485231</td>\n      <td>0.063833</td>\n      <td>-0.051719</td>\n      <td>-0.474776</td>\n      <td>-0.157346</td>\n      <td>...</td>\n      <td>-1.005212</td>\n      <td>-0.636474</td>\n      <td>-1.060995</td>\n      <td>-0.265033</td>\n      <td>0.261927</td>\n      <td>0.475789</td>\n      <td>0.396691</td>\n      <td>-0.483419</td>\n      <td>-0.462064</td>\n      <td>0.753480</td>\n    </tr>\n    <tr>\n      <th>30327</th>\n      <td>-0.043228</td>\n      <td>0.059844</td>\n      <td>-0.098564</td>\n      <td>-0.108816</td>\n      <td>-0.169434</td>\n      <td>0.162772</td>\n      <td>-0.034107</td>\n      <td>0.113279</td>\n      <td>0.336566</td>\n      <td>-0.003216</td>\n      <td>...</td>\n      <td>-0.739609</td>\n      <td>0.251306</td>\n      <td>-0.288614</td>\n      <td>-0.280471</td>\n      <td>-1.015869</td>\n      <td>-0.525669</td>\n      <td>-0.590650</td>\n      <td>-0.483419</td>\n      <td>-0.495948</td>\n      <td>-0.308999</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 518 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "229beb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the initial weights and input/output \n",
    "\n",
    "(first_layer_size, second_layer_size, third_layer_size, forth_layer_size) = [518 // 2, 518 // 4, 518 // 8, 518 // 16]\n",
    "x = tf.placeholder(tf.float32, [None, 518])\n",
    "y = tf.placeholder(tf.float32, [None, 161])\n",
    "\n",
    "weight_first = tf.Variable(tf.truncated_normal([518, first_layer_size], stddev=0.3, dtype=tf.float32))\n",
    "bias_first = tf.Variable(tf.constant(0, shape=[first_layer_size], dtype=tf.float32))\n",
    "activation_first = tf.nn.relu6(tf.matmul(x, weight_first) + bias_first)\n",
    "\n",
    "weight_second = tf.Variable(tf.truncated_normal([first_layer_size, second_layer_size], stddev=0.3, dtype=tf.float32))\n",
    "bias_second = tf.Variable(tf.constant(0, shape=[second_layer_size], dtype=tf.float32))\n",
    "activation_second = tf.nn.relu6(tf.matmul(activation_first, weight_second) + bias_second)\n",
    "\n",
    "weight_third = tf.Variable(tf.truncated_normal([second_layer_size, third_layer_size], stddev=0.3, dtype=tf.float32))\n",
    "bias_third = tf.Variable(tf.constant(0, shape=[third_layer_size], dtype=tf.float32))\n",
    "activation_third = tf.nn.relu6(tf.matmul(activation_second, weight_third) + bias_third)\n",
    "\n",
    "weight_forth = tf.Variable(tf.truncated_normal([third_layer_size, forth_layer_size], stddev=0.3, dtype=tf.float32))\n",
    "bias_forth = tf.Variable(tf.constant(0, shape=[forth_layer_size], dtype=tf.float32))\n",
    "activation_forth = tf.nn.relu6(tf.matmul(activation_third, weight_forth) + bias_forth)\n",
    "\n",
    "weights_output = tf.Variable(tf.truncated_normal([forth_layer_size, 161], stddev=0.3, dtype=tf.float32))\n",
    "bias_output = tf.Variable(tf.constant(0, shape=[161], dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2e39b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating prediction, training and cross-entropy methods\n",
    "pred = tf.nn.softmax(tf.matmul(activation_forth, weights_output) + bias_output)\n",
    "loss = -tf.reduce_sum(y * tf.log(tf.clip_by_value(pred, 1e-10, 1.0)))\n",
    "training_step = tf.train.AdamOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e435dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting session and starting to run\n",
    "training_sess = tf.Session()\n",
    "training_sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5a93e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting function for correct prediction and accuracy\n",
    "correct = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d33deb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - accuracy for epoch 49.69252347946167 - max accuracy: 49.69252347946167\n",
      "validation set accuracy: 48.52822721004486\n",
      "epoch: 1000 - accuracy for epoch 61.016178131103516 - max accuracy: 61.016178131103516\n",
      "validation set accuracy: 60.080647468566895\n",
      "epoch: 2000 - accuracy for epoch 60.33318042755127 - max accuracy: 61.016178131103516\n",
      "validation set accuracy: 58.40725898742676\n",
      "epoch: 3000 - accuracy for epoch 59.637582302093506 - max accuracy: 61.016178131103516\n",
      "validation set accuracy: 58.16532373428345\n",
      "epoch: 4000 - accuracy for epoch 60.15424132347107 - max accuracy: 61.016178131103516\n",
      "validation set accuracy: 59.15322303771973\n",
      "epoch: 5000 - accuracy for epoch 60.4516327381134 - max accuracy: 61.016178131103516\n",
      "validation set accuracy: 58.02419185638428\n",
      "epoch: 6000 - accuracy for epoch 60.746508836746216 - max accuracy: 61.016178131103516\n",
      "validation set accuracy: 59.435486793518066\n",
      "epoch: 7000 - accuracy for epoch 61.495035886764526 - max accuracy: 61.495035886764526\n",
      "validation set accuracy: 60.26209592819214\n",
      "epoch: 8000 - accuracy for epoch 59.48888659477234 - max accuracy: 61.495035886764526\n",
      "validation set accuracy: 57.72177577018738\n",
      "epoch: 9000 - accuracy for epoch 59.909772872924805 - max accuracy: 61.495035886764526\n",
      "validation set accuracy: 57.90322422981262\n",
      "epoch: 10000 - accuracy for epoch 61.12959384918213 - max accuracy: 61.495035886764526\n",
      "validation set accuracy: 59.07257795333862\n"
     ]
    }
   ],
   "source": [
    "#training loop:\n",
    "saver = tf.train.Saver()\n",
    "epochs = 10001\n",
    "batch_size = 389\n",
    "iterations = int((x_train.shape[0]) / batch_size)\n",
    "maxAccuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    ptr = 0\n",
    "    for iteration in range(iterations):\n",
    "        batch_input = x_train[ptr:ptr + batch_size]\n",
    "        batch_label = y_train[ptr:ptr + batch_size]\n",
    "        ptr = (ptr + batch_size) % x_train.shape[0]\n",
    "        _, err = training_sess.run([training_step, loss], feed_dict={x: batch_input, y: batch_label})\n",
    "    if epoch % 1000 == 0:\n",
    "        currAccuracy = training_sess.run(accuracy, feed_dict={x: x_train, y: y_train})\n",
    "        valid_accuracy = training_sess.run(accuracy, feed_dict={x: x_valid, y: y_valid})\n",
    "        if currAccuracy > maxAccuracy:\n",
    "            saver.save(training_sess, \"best_mlp_4_layers\", global_step=1)\n",
    "            maxAccuracy = currAccuracy\n",
    "        print(f\"epoch: {epoch} - accuracy for epoch {currAccuracy*100} - max accuracy: {maxAccuracy*100}\")\n",
    "        print(f\"validation set accuracy: {valid_accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "482c54cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(39678, 518)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61129594\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = training_sess.run(accuracy, feed_dict={x: x_train, y: y_train})\n",
    "print(train_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5907258\n"
     ]
    }
   ],
   "source": [
    "valid_accuracy = training_sess.run(accuracy, feed_dict={x: x_valid, y: y_valid})\n",
    "print(valid_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b120b38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5975807\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = training_sess.run(accuracy, feed_dict={x: x_test, y: y_test})\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}